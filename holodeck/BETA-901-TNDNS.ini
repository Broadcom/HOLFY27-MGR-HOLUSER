# config.ini - version v2.0 - 27-January 2026
# BETA-901-TNDNS - HOL VCF Single Site Test
[VPOD]
# change to your vPod SKU
vPod_SKU = BETA-901-TNDNS

# the type of VCF deployment (HOL, Ninja, Discovery, etc.)
labtype = Discovery

# lock the holuser account on the Manager if VLP deployment (true or false)
lockholuser = true

# minutes before fail - discuss with core team if changing
maxminutes = 90

# install Odyssey client (true or false)
odyssey = false

# labcheck interval in minutes (0 to disable)
labcheckinterval = 0

# Custom conky title (if not specified, uses vPod_SKU)
conky_title = FY 27 Single Site Test

# DNS record import - inline CSV format: zone,name,type,value
# Multiple records separated by newlines (with indentation) or semicolons
# See: https://raw.githubusercontent.com/burkeazbill/tdns-mgr/refs/heads/main/new-dns-records.csv
# Uncomment and add records as needed:
new-dns-records = site-a.vcf.lab,gitlab,A,10.1.10.211
     site-a.vcf.lab,harbor,A,10.1.10.212
     site-a.vcf.lab,git,CNAME,gitlab.site-a.vcf.lab


[RESOURCES]
# List the ESXi hosts to check on port 22 and MM yes/no at vPod start
# indentation is important
# if you have no ESXiHosts comment out the next line
ESXiHosts = esx-01a.site-a.vcf.lab:no
 esx-02a.site-a.vcf.lab:no
 esx-03a.site-a.vcf.lab:no
 esx-04a.site-a.vcf.lab:no

# List the vCenters to check
# specify the host type (linux, windows, esx)
# specify the account to use (required)
# vSphere 8 base templates
vCenters = vc-mgmt-a.site-a.vcf.lab:linux:administrator@vsphere.local
 #vc-mgmt-b.site-b.vcf.lab:linux:administrator@vsphere2.local
 # vSphere 6.7 base templates
 #vc-mgmt-01a.site-a.vcf.lab:linux:administrator@regiona.local
 #vc-mgmt-01b.site-a.vcf.lab:linux:administrator@regionb.local
 # vSphere 7 base templates
 #vc-mgmt-01a.site-a.vcf.lab:linux:administrator@vsphere.local
 #vc-mgmt-01b.site-a.vcf.lab:linux:administrator@vsphere2.local

# Datastores to be checked
#  hosts will be rescanned if these are missing
#Datastores = stg-01a.site-a.vcf.lab:RegionA01-ISCSI01-COMP01A
# stg-01a.site-a.vcf.lab:RegionB01-ISCSI01-COMP01B
Datastores = VSAN:vsan-mgmt-01a
 #stg-01a.site-a.vcf.lab:ISCSI01-COMP01B
 #VSAN:RegionA01-VSAN-COMP01A
 #VSAN:RegionB01-VSAN-COMP01B

# clustername:on|off # specify DRS configuration at vPod start
Clusters = cluster-mgmt-01a:off
 #RegionB01-COMP01B:off

# Nested Virtual Machines to be powered on
#  if multiple vCenters, specify the FQDN of the owning vCenter after the colon
# Optionally indicate a pause with the "Pause" record.  In this case the number 
#  after the colon is the number of seconds to wait before continuing.
VMs = sddcmanager-a:vc-mgmt-a.site-a.vcf.lab
 ops-a:vc-mgmt-a.site-a.vcf.lab
 opscollector-01a:vc-mgmt-a.site-a.vcf.lab
 opslcm-a:vc-mgmt-a.site-a.vcf.lab
 opslogs-01a:vc-mgmt-a.site-a.vcf.lab
 opsnet-01a:vc-mgmt-a.site-a.vcf.lab
 opsnetcollector-01a:vc-mgmt-a.site-a.vcf.lab
 vidb-01a-npzd6:vc-mgmt-a.site-a.vcf.lab
 vidb-01a-pqn7f:vc-mgmt-a.site-a.vcf.lab
 vidb-01a-qll8x:vc-mgmt-a.site-a.vcf.lab
  
 #auto-a:vc-mgmt-a.site-a.vcf.lab
 #Pause:10
 #core-B:vc-mgmt-b.site-b.vcf.lab
 #Pause:10
 #linux-desk-01a:vc-mgmt-01a.site-a.vcf.lab
 # if not using vCenter, specify the owning ESXi host
 #single-vm:esx-01a.site-a.vcf.lab

# as with vVMs, the format of these entries is VAPPNAME:VCENTER
# uncomment the next line if you have nested vApps
#vApps = YourvApp:vc-mgmt-01a.site-a.vcf.lab
 # YourOthervApp:vc-mgmt-01a.site-a.vcf.lab

# IP addresses to be pinged
Pings = 10.1.10.129
 10.1.10.131

# Windows services to be checked / started (must keep all ":")
# uncomment the next line then add or edit if a Windows service is present in your lab
#WindowsServices = server:service:passwd:waitsec
 # Site A SRM embedded database
 #srm-01a.site-a.vcf.lab:vmware-dr-vpostgres::10
 # Site A SRM server
 #srm-01a.site-a.vcf.lab:vmware-dr::10
 # Site B SRM embedded database::10
 #srm-01b.site-b.vcf.lab:vmware-dr-vpostgres::10
 # Site B SRM server
 #srm-01b.site-b.vcf.lab:vmware-dr::10

# Linux services to be checked / started (must keep all ":")
# uncomment the next line then add or edit if a Windows service is present in your lab
#LinuxServices = server:service:passwd:waitsec
 # For vSphere 6.7 and 7.x, uncomment the vcsa-01x lines as needed
 # For vSphere 8.x, leave the vcsa-01x lines commented out
 # example to check vSphere ui service (site A)
 #vc-mgmt-01a.site-a.vcf.lab:vsphere-ui::5
 # example to check vSphere ui service (site B)
 #vc-mgmt-01b.site-b.vcf.lab:vsphere-ui::5

# TCP ports to be checked
# format is hostname:<port number>
TCPServices = vc-mgmt-a.site-a.vcf.lab:443
 #vc-mgmt-b.site-b.vcf.lab:443

# List Kubernetes machines to check for SSL certifcate renewal
# EXPERIMENTAL
# primary host:privileged account:password:renewal command
# uncomment the next line then add or edit if Kubernetes is present in your lab
#Kubernetes = k8s-master.site-a.vcf.lab:root:************:kubeadm certs renew all
 #k8s-master.site-a.vcf.lab:root:************:kubeadm alpha certs renew all

# URLs to be checked for specified text in response
# the response text follows the comma:  "URL,response"
# if no response is specified, an HTTP status code of 200 is verified.
# for vmware.com must use www.vmware.com and not just vmware.com
URLS = https://www.vmware.com/,VMware
 # vSphere 8 base templates
 https://vc-mgmt-a.site-a.vcf.lab/ui/,loading-container
 https://ops-a.site-a.vcf.lab/ui/,VMware Cloud Foundation Operations
 https://sddcmanager-a.site-a.vcf.lab/ui/,SDDC Manager
 #https://vc-mgmt-b.site-b.vcf.lab/ui/,loading-container
 #http://stg-01a.site-a.vcf.lab/account/login,TrueNAS
 #https://checkin.hol.vmware.com,Student
 # vSphere 6.7 base templates
 #https://vc-mgmt-01a.site-a.vcf.lab/vsphere-client/,vSphere Web Client
 #https://vc-mgmt-01a.site-a.vcf.lab/ui/resources/js/redirect.js,redirectIfNeeded
 #https://vc-mgmt-01b.site-b.vcf.lab/vsphere-client/,vSphere Web Client
 #https://vc-mgmt-01b.site-b.vcf.lab/ui/resources/js/redirect.js,redirectIfNeeded
 # vSphere 7 base templates
 #https://vc-mgmt-01a.site-a.vcf.lab/ui/,loading-container
 #https://vc-mgmt-01b.site-b.vcf.lab/ui/,loading-container
 #https://vc-mgmt-01b.site-b.vcf.lab/ui/,loading-container


[VCF]
# the ESXi hosts that bootstrap VCf
vcfmgmtcluster = esx-01a.site-a.vcf.lab:esx
 esx-02a.site-a.vcf.lab:esx
 esx-03a.site-a.vcf.lab:esx
 esx-04a.site-a.vcf.lab:esx

# the VCF management datastore name
vcfmgmtdatastore = vsan-mgmt-01a

# VCF NSX Manager L2 and ESXi host
vcfnsxmgr = nsx-mgmt-01a:esx-01a.site-a.vcf.lab
 #nsx-wld01-01a:esx-01a.site-a.vcf.lab

# the VCF NSX Edge L2 VMs
vcfnsxedges = edge-mgmt-01a:esx-02a.site-a.vcf.lab
 edge-mgmt-02a:esx-02a.site-a.vcf.lab
 #edge-mgmt-01a:esx-04a.site-a.vcf.lab
 #edge-mgmt-02a:esx-02a.site-a.vcf.lab

# Post-Edge VMs - boot immediately after NSX Edges, before vCenter
# These VMs need extra boot time but don't need to wait for vCenter
# Format: vmname:esxhost
vcfpostedgevms = auto-a:esx-04a.site-a.vcf.lab

# the L2 NSX management vCenter - use actual VM name here
vcfvCenter = vc-mgmt-a:esx-02a.site-a.vcf.lab


[VCFFINAL]

# Aria Automation VMs
vravms = auto-a-:vc-mgmt-a.site-a.vcf.lab
 sddcmanager-a:vc-mgmt-a.site-a.vcf.lab

# Aria Automation URLs to check
vraurls = https://auto-a.site-a.vcf.lab/login,VCF Automation


[SHUTDOWN]
# Shutdown configuration for VCFshutdown.py
# NOTE: NSX components, vCenters, and ESXi hosts are now read from the [VCF] section
# to avoid duplicate configuration and potential inconsistencies.
# The following settings are ONLY used by the [SHUTDOWN] section:

# Fleet Operations (Aria Suite Lifecycle)
fleet_fqdn = opslcm-a.site-a.vcf.lab
fleet_username = admin@local
fleet_products = vra,vrni,vrops,vrli

# Docker containers
shutdown_docker = true
docker_host = docker.site-a.vcf.lab
docker_user = holuser
docker_containers = gitlab,ldap,poste.io,flask

# WCP vCenters to stop WCP service (from [RESOURCES] vCenters with wld in name)
# Only specify if you need to override the automatic detection
#wcp_vcenters = vc-wld01-a.site-a.vcf.lab

# VM patterns to find and shutdown (regex)
vm_patterns = ^kubernetes-cluster-.*$
  ^dev-project-.*$
  ^cci-service-.*$
  ^SupervisorControlPlaneVM.*$

# Specific workload VMs to shutdown
workload_vms = core-a
  core-b
  hol-ubuntu-001

# ESXi username for SSH operations
esx_username = root

# vSAN settings
vsan_enabled = true
# vSAN timeout in seconds (45 minutes = 2700 seconds)
vsan_timeout = 2700

# Host shutdown
shutdown_hosts = true

# NOTE: The following are now read from [VCF] section automatically:
# - NSX Edges: [VCF] vcfnsxedges (filtered by "wld" for workload, "mgmt" for management)
# - NSX Managers: [VCF] vcfnsxmgr (filtered by "wld" for workload, "mgmt" for management)
# - ESXi Hosts: [VCF] vcfmgmtcluster
# - vCenters: [VCF] vcfvCenter (filtered by "wld" for workload, "mgmt" for management)
